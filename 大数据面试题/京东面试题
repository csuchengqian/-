学长一：
  自我介绍，介绍一下你们的数仓部分
  1.如何保证hdfs的数据load到ods层，数据不丢失？ 直接把数据干掉，用sqoop脚本把指定表的数据重跑一边。
  2.采集过程如何保证数据不丢失？  flume断点续传、file channel，kafka多副本等机制、ack=-1 
  3.presto讲一讲
  4.superset讲一讲
  5.离线用的是spark引擎还是mr引擎？ 
  6.spark遇到过哪些问题？
  7.spark对小文件的处理？
  8.ods数据的保存格式？   lzop
  9.数仓各层级中，你主要负责哪些部分？ 全程负责
  10.azkaban除了任务调度还做了什么？  什么都干不了，还能报警
  11.任务失败除了重试和重跑，还做了什么？ 
  12.sqoop导数据的时候失败了怎么办？  从mysql导到hdfs，可以重跑，因为用的into overwrite ；从hdfs写到mysql, 

学长二：
  1.yarn调度器
  2.问了好多linux命令 如何展示文件夹下文件个数  ls -l | grep "^-" | wc -l
  3.hive运行map数量过多，如何解决  
  4.hive数据倾斜 如何知道发生数据倾斜  yarn上看 
  5.hive大表join大表，如何避免数据倾斜，如何定位引起数据倾斜的key
  6.hive内部表、外部表区别，非要删外部表的元数据呢  alter table xxx set tblproperties ("EXTERNAL" = "FLASE")
  7.hive的集合数据类型  数组 、map 、结构体
  8.很长的脚本，里面的sql语句，如何定位错误发生在哪 
  9.介绍项目
  10.数仓如何保证维度的一致性    
  11.拉链表 几种实现方式
  12.分区表要增加字段怎么做
  13.数据集市和数据仓库区别
  14.sql题 没截图 1连续获得冠军  2竖表转横表
