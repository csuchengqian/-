学长一：
  这个公司有离线和实时两条线，都在做，技术问上个公司的位置
  1.Kafka积压
      消费消息的能力如果小于生产消息的能力，就会逐渐积压消息。
      如果线上突然挤压，解决方式是先找到积压的代码原因，如果能处理就直接处理了，如果短时间不能优化则提高消费端的实例数量，
  如果没有多余资源，则只能给生产端降级，优先提供给重要的服务，让系统能正常工作。
  
      Kafka积压可以在两方面进行优化
        （1）增加分区，同时要求消费者增加对应的cpu核数
             分区和CPU为一比一
             在任务提交时指定参数：--executor-cores X
        （2）加快消费者的消费速度
             flume/sparkstreaming   batchsize 1000条/s=>2000条/s
           
  2.项目中遇到什么问题
  
  3.Hive自定义函数如何实现  注册完之后怎么做的
        自定义类继承GenericUDF/GenericUDTF。
        之后打jar包上传hive中或者HDFS上。
        
        怎么做：使用时和内置函数使用方式一样。
                删除时：
                        如果是临时函数：在关闭当前session后自动删除
                        如果是永久函数: drop function xxxx;
                
  4.现在有一个文本要往hdfs存，通过什么方式能知道它的行数 可以用脚本、shell、python
        vim-> :set nu 显示行号
    
  5.你们公司Hbase中row Key的设计原则 
        对于订单状态表采用的是：reverser(orderId)+(Long.MAX_VALUE-timestamp)
                               这样设计可以很好的避免Region热点,其次可以按照时间倒序显示，获取最新订单。
        登录、下单等临时存储采用：salt+eventId+Date
                                 对于热数据，采用家宴的方式可以增加并发性，在查询的时候可以将数据分为N个split同时做scan操作，
                                 增加并发度能够将整体查询速度提升5-10倍。随后eventId和Date用来做范围scan，在我们查询场景中，大部分
                                 都指定了eventId，同时，通过salt+eventId可以保证不会形成热点。Date放在第三个位置可以做scan，批量scan可以做到毫秒级返回。
  
  6.Spark中的stage如何划分的
        
  
  7.Spark中的sparkcontext是起到了什么作用
        SparkContext是Spark应用的入口，负责整个集群的交互，包括创建RDD。
        是Driver程序的一部分，向资源管理器申请spark所需的资源Executor，资源管理器在各个worker上分配一定的Executor。
        
  8.实时项目中  日志数据发送到Kafka后数据是什么样的
        因为我们采用的Maxwell监控MySql，所以数据到达Kafka是JSON格式的。
  9.建模的过程  
        
  10.数据是怎么到Kafka的，生产方是怎么做的
        我们这里的数据分为业务数据和用户行为数据
        业务数据用过业务服务器写入MySql中，我们采用Maxwell监控MySql的binlog将数据发送到Kafka中。(这里可以说一下Maxwell和Canal的优劣区别等)
        用户行为数据我们通过前端埋点，用Flume采集到Kafka中。(我们Flume采用的Taildir Source,使用Kafka Channel，因为Kafka Channel优于Memory Channel+Kafka Sink)
                                                            
